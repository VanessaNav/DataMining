{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanessa Navarro Coronado e Iván Sánchez Castellanos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kanncaa1/roc-curve-with-k-fold-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2 - Clasificación supervisada en scikit-learn --> VOICE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a estudiar el dataset Voice. Probaremos los clasificadores de Árbol de Decisión y KNN, y analizaremos cuál es mejor en cada caso. Además, trataremos de descubrir las configuraciones óptimas de dichos algoritmos, y realizaremos un breve estudio sobre ellos.\n",
    "\n",
    "Además, en la parte extra utilizaremos un Naive Bayes, usando el mismo procedimiento que seguimos para los clasificadores anteriormente citados.\n",
    "\n",
    "Para comenzar, como siempre, lo primero que hacemos es importar los paquetes necesarios, e inicializar nuestra semilla para nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6342\n",
    "np.random.seed(6342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos los datos del dataset Voice. Este será separado en dos conjuntos, uno con los atributos y otro con la clase del dataset. Esto es necesario para que la libreria scikit learn pueda ser utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the file path to fit your system\n",
    "dfVoice = pd.read_csv(\"../data/voice.csv\", dtype={ \"label\": 'category'})\n",
    "dfAttributesVoice = dfVoice.drop('label', 1)\n",
    "dfLabelVoice = dfVoice['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datasets, debemos dividirlos en dos conjuntos de Train y Test para poder realizar nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train/test split for our experiments\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_attsVoice, test_attsVoice, train_labelVoice, test_labelVoice = train_test_split( \n",
    "    dfAttributesVoice,\n",
    "    dfLabelVoice,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=dfLabelVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Selección y evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección realizaremos experimentos utilizando el algoritmo GridSearch de la librería scikit-learn para descubrir las configuraciones óptimas de los clasificadores DecisionTree y KNN para el dataset Voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos a seguir en este apartado son:\n",
    "* Crear un Pipeline con dos pasos:\n",
    "    - Un objeto de la clase Imputer que se encarga de realizar el tratamiento de valores perdidos. En nuestro caso, imputaremos los valores NaN de los datasets con la media.\n",
    "    - Un clasificador como estimador (árbol de decisión o KNN en nuestro caso).\n",
    "* Crear un objeto de la clase GridSearchCV, al que le pasaremos:\n",
    "    - el estimador que usamos en el Pipeline, \n",
    "    - los hiperparámetros del clasificador que queremos tener en cuenta a la hora de buscar la configuración óptima.\n",
    "    - También debemos indicar qué tipo de métrica usaremos para valorar las configuraciones,\n",
    "    - cuántos folds se deben realizar en el proceso de validación cruzada que realiza el GridSearchCV. Si en este campo especificamos un objeto de la clase StratifiedKFold con 10 folds y nuestra semilla, podrá realizar un proceso de validación cruzada estratificada.\n",
    "    - iid = False, para que la evaluación de los resultados se haga sobre una media aritmética, y no sobre una media ponderada.\n",
    "* Entrenar y validar el clasificador con los datos de nuestros datasets, y analizar los resultados obtenidos (accuracy, precision y recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Árbol de decisión con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con el clasificador DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# Cargamos el arbol de decision\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación creamos un Pipeline con dos pasos: el primero es imputar los valores perdidos siguiendo la estrategia de rellenar con la media, y el segundo paso es un clasificador DecisionTree, con su semilla para poder hacer reproducibles nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the pipeline as a set of tuples\n",
    "estimatorTree = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"Tree\", tree.DecisionTreeClassifier(random_state=seed))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí definimos nuestro GridSearch con los parámetros elegidos. Como estimador debemos pasarle el que usamos en nuestro Pipeline.\n",
    "\n",
    "En nuestro caso hemos elegido los parámetros 'criterion' (puede ser \"gini\", que usa la impureza Gini como función, o “entropy”, usando la ganancia de información), 'max_depth' (para indicar la máxima profundidad del árbol), y 'min_samples_leaf' (para indicar el número mínimo de ejemplos que queremos que haya en cada hoja del árbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTree = GridSearchCV(\n",
    "    estimator = estimatorTree,\n",
    "    param_grid =\n",
    "        {'Tree__criterion': [\"entropy\",\"gini\"],'Tree__max_depth': [3, 5, 10, None], 'Tree__min_samples_leaf': [3,5,10]},\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si asignamos el valor 'None' al parámetro 'max_depth', el clasificador intentará llegar a la máxima profundidad del árbol por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de pasar el GridSearch, ejecutamos con el dataset para entrenar el clasificador con el conjunto de Train, validamos con nuestro conjunto de Test, y después imprimimos el accuracy obtenido con la mejor configuración de parámetros del árbol encontrada por nuestro GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoice = clfTree.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoice = clfTree.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, nos parece interesante mostrar la mejor configuración de los parámetros del árbol que ha encontrado el GridSearch. En este caso, la mejor configuración es utilizar el criterio de entropía para evaluar las variables del árbol, emplear una profundidad máxima del árbol de 5, y un número mínimo de ejemplos por hoja igual a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tree__criterion': 'entropy',\n",
       " 'Tree__max_depth': 5,\n",
       " 'Tree__min_samples_leaf': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree):')\n",
    "clsTreeVoice.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del accuracy, también es interesante mostrar la matriz de confusión obtenida, y las medidas de precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[307,  10],\n",
       "       [ 15, 302]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice Tree:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96845425867507884"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice Tree:')\n",
    "metrics.recall_score(test_labelVoice, predictionTreeVoice, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95341614906832295"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice Tree:')\n",
    "metrics.precision_score(test_labelVoice, predictionTreeVoice, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. KNN con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a usar un KNN como clasificador para nuestro Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Pipeline con el imputer como primer paso, y como segundo paso, el clasificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the pipeline as a set of tuples\n",
    "estimatorKNN = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"KNN\", neighbors.KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos los parámetros del algoritmo de KNN que queremos que el GridSearch tenga en cuenta a la hora de buscar la configuración óptima. En el algoritmo KNeighborsClassifier no se nos permite elegir un random_state como en el caso del árbol para poder hacer reproducibles nuestros experimentos, por lo que solo usaremos la semilla en el proceso de validación cruzada que se realiza en el GridSearch.\n",
    "\n",
    "En nuestro caso, para el KNN hemos añadido el número de vecinos, y el tipo de métrica a utilizar para valorar las distancias de los vecinos (puede ser la distancia o la inversa de la distancia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNN = GridSearchCV(\n",
    "    estimator = estimatorKNN,\n",
    "    param_grid = \n",
    "        { 'KNN__n_neighbors' : [1,2,3,4,5], 'KNN__weights': ['uniform','distance'] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entrenamos, validamos y obtenemos el accuracy en los datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsKNNVoice = clfKNN.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoice = clfKNN.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuál ha sido la mejor configuración de parámetros obtenida por el GridSearch. En este caso es utilizar 4 vecinos, usando la métrica inversa para medir las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNN__n_neighbors': 4, 'KNN__weights': 'distance'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN):')\n",
    "clsKNNVoice.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos la matriz de confusión, precision y recall obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215, 102],\n",
       "       [ 81, 236]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice KNN:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionKNNVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67823343848580442"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice KNN:')\n",
    "metrics.recall_score(test_labelVoice, predictionKNNVoice, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72635135135135132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice KNN:')\n",
    "metrics.precision_score(test_labelVoice, predictionKNNVoice, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado intentaremos analizar cuál de los clasificadores ha obtenido mejores resultados en el dataset estudiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de accuracy para el árbol de decisión y el KNN con k=4, son: \n",
    "* Accuracy Voice Tree: 0.9605678233438486\n",
    "* Accuracy Voice 4-NN: 0.71135646687697163\n",
    "\n",
    "En cuanto a los resultados de recall tenemos:\n",
    "* Recall Voice Tree: 0.96845425867507884\n",
    "* Recall Voice 4-NN: 0.67823343848580442\n",
    "\n",
    "Y los de precision:\n",
    "* Precision Voice Tree: 0.95341614906832295\n",
    "* Precision Voice 4-NN: 0.72635135135135132\n",
    "\n",
    "Por tanto, podemos concluir que el mejor modelo es el obtenido con el árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementación de GridSearch manualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado realizamos una implementación manual de un GridSearh básico, con su constructor, y las funciones fit y predict, que son las que utilizamos en esta práctica.\n",
    "\n",
    "Nuestra clase GridS tiene como atributos:\n",
    "* estim: estimador o clasificador a evaluar,\n",
    "* crossval: cómo realizar el proceso de validación cruzada durante la evaluación,\n",
    "* score: tipo de métrica a utilizar para la evaluación de la configuración óptima,\n",
    "* keys: nombre de los parámetros del clasificador a tener en cuenta en la evaluación,\n",
    "* v: lista con todas las posibles combinaciones de parámetros del clasificador,\n",
    "* bestScore: mejor puntuación obtenida con la configuración de parámetros del clasificador,\n",
    "* bestParams: mejor configuración de parámetros del clasificador.\n",
    "\n",
    "La función fit se encarga de realizar la validación cruzada para cada una de las diferentes combinaciones de parámetros contenidas en self.v, obteniendo así aquella configuración que ofrezca una mayor puntuación. Una vez obtenida, entrena el clasificador con el conjunto de datos que se le pasa como parámetro a la función fit.\n",
    "\n",
    "La función predict simplemente hace la validación del clasificador con el conjunto que reciba como parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "class GridS(object):\n",
    "    def __init__(self,estim, paramG, score, crossval):\n",
    "        items = paramG.items()\n",
    "        self.keys, values = zip(*items)\n",
    "        self.v = list(product(*values))\n",
    "        self.estim=estim\n",
    "        self.crossval=crossval\n",
    "        self.score=score\n",
    "        self.bestParams = []\n",
    "            \n",
    "    def fit(self,atts,label):\n",
    "        self.bestScore=0\n",
    "        for param in self.v:\n",
    "            params = dict(zip(self.keys,param))\n",
    "            self.estim.set_params(**params)\n",
    "            scores = cross_val_score(estimator=self.estim, \n",
    "                                     X=atts, y=label, \n",
    "                                     scoring=self.score, \n",
    "                                     cv=self.crossval)\n",
    "            if self.bestScore < scores.mean():\n",
    "                self.bestScore=scores.mean()\n",
    "                self.bestParams=params\n",
    "        self.estim.set_params(**self.bestParams)\n",
    "        self.estim.fit(atts,label)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, atts):\n",
    "        return self.estim.predict(atts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. KNN con GridSearch manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un Pipeline que tiene como primer paso el Imputer de los datos, y como segundo paso el clasificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorGSKNN = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"myKNN\", neighbors.KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que hicimos anteriormente con el GridSearch de scikit, creamos un objeto de la clase GridS. Le pasamos nuestro pipeline, y le indicamos que obtenga la mejor configuración de parámetros atendiendo al número de vecinos (de 1 a 5 vecinos), y el tipo de métrica a utilizar para valorar la distancia (uniforme o inversa de la distancia). El tipo de métrica a utilizar será de nuevo el accuracy, y utilizaremos un proceso de validación cruzada estratificada de 10 folds, con nuestra semilla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsKNN = GridS(\n",
    "    estim = estimatorGSKNN,\n",
    "    paramG = \n",
    "        { 'myKNN__n_neighbors' : [1,2,3,4,5], 'myKNN__weights': ['uniform','distance'] },\n",
    "    score = 'accuracy',\n",
    "    crossval = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación utilizamos nuestro GridS en el dataset y evaluamos los resultados. Como vemos, son los mismos que obtuvimos usando el GridSearch de scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsKNNVoiceGS = gsKNN.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoiceGS = gsKNN.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN + GridS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoiceGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN + GridS):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'myKNN__n_neighbors': 4, 'myKNN__weights': 'distance'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN + GridS):')\n",
    "clsKNNVoiceGS.bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice KNN + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72635135135135132"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice KNN + GridS:')\n",
    "metrics.precision_score(test_labelVoice, predictionKNNVoiceGS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice KNN + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67823343848580442"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice KNN + GridS:')\n",
    "metrics.recall_score(test_labelVoice, predictionKNNVoiceGS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Árbol de decisión con GridSearch manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que hicimos anteriormente con el GridSearch de scikit, creamos un objeto de la clase GridS. Le pasamos un clasificador DecisionTree, y le indicamos que obtenga la mejor configuración de parámetros atendiendo al criterio de evaluación (entropía o gini), la máxima profundidad del árbol, y el número mínimo de ejemplos por hoja. El tipo de métrica a utilizar será de nuevo el accuracy, y utilizaremos un proceso de validación cruzada estratificada de 10 folds, con nuestra semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorGSTree = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"myTree\", tree.DecisionTreeClassifier(random_state=seed),)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsTree=GridS(\n",
    "    estim = estimatorGSTree,\n",
    "    paramG=\n",
    "        {'myTree__criterion': [\"entropy\",\"gini\"],'myTree__max_depth': [3, 5, 10, None], 'myTree__min_samples_leaf': [3,5,10]},\n",
    "    score='accuracy',\n",
    "    crossval=StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación utilizamos nuestro GridS en el dataset y evaluamos los resultados. Como vemos, son los mismos que obtuvimos usando el GridSearch de scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoiceGS = gsTree.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoiceGS = gsTree.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree + GridS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoiceGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree + GridS):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'myTree__criterion': 'entropy',\n",
       " 'myTree__max_depth': 5,\n",
       " 'myTree__min_samples_leaf': 10}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree + GridS):')\n",
    "clsTreeVoiceGS.bestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice Tree + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95341614906832295"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice Tree + GridS:')\n",
    "metrics.precision_score(test_labelVoice, predictionTreeVoiceGS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice Tree + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96845425867507884"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice Tree + GridS:')\n",
    "metrics.recall_score(test_labelVoice, predictionTreeVoiceGS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extras: Algoritmo RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección realizaremos experimentos utilizando el algoritmo RandomizedSearch de la librería scikit-learn para descubrir las configuraciones óptimas de los clasificadores DecisionTree y KNN\n",
    ". Seguiremos el mismo proceso que hicimos con GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Árbol de decisión con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos un Pipeline con dos pasos: el primero es imputar los valores perdidos siguiendo la estrategia de rellenar con la media, y el segundo paso es un árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the pipeline as a set of tuples\n",
    "estimatorTreeRS = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"RSTree\", tree.DecisionTreeClassifier(random_state=seed))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí definimos nuestro RandomizedSearch con los parámetros elegidos, usando nuestro Pipeline.\n",
    "\n",
    "En nuestro caso hemos elegido los parámetros 'criterion' (puede ser \"gini\", que usa la impureza Gini como función, o “entropy”, usando la ganancia de información), 'max_depth' (para indicar la máxima profundidad del árbol), y 'min_samples_leaf' (para indicar el número mínimo de ejemplos que queremos que haya en cada hoja del árbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTreeRS = RandomizedSearchCV(\n",
    "    estimator = estimatorTreeRS,\n",
    "    param_distributions =\n",
    "        {'RSTree__criterion': [\"entropy\",\"gini\"],'RSTree__max_depth': [3, 5, 10, None], 'RSTree__min_samples_leaf': [3,5,10]},\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de crear el Pipeline, lo ejecutamos con el dataset para entrenar el clasificador con el conjunto de Train, validamos con nuestro conjunto de Test, y después imprimimos el accuracy obtenido con la mejor configuración de parámetros del árbol encontrada por nuestro RandomizedSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoiceRS = clfTreeRS.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoiceRS = clfTreeRS.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree with RS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, nos parece interesante mostrar la mejor configuración de los parámetros del árbol que ha encontrado el RandomizedSearch. En este caso, la mejor configuración es utilizar el criterio de entropía para evaluar las variables del árbol, emplear una profundidad máxima del árbol de 5, y un número mínimo de ejemplos por hoja igual a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree) con RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RSTree__criterion': 'entropy',\n",
       " 'RSTree__max_depth': 5,\n",
       " 'RSTree__min_samples_leaf': 5}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree) con RS:')\n",
    "clsTreeVoiceRS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del accuracy, también es interesante mostrar la matriz de confusión obtenida, y las medidas de precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[305,  12],\n",
       "       [ 15, 302]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice Tree with RS:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionTreeVoiceRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96214511041009465"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice Tree with RS:')\n",
    "metrics.recall_score(test_labelVoice, predictionTreeVoiceRS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.953125"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice Tree with RS:')\n",
    "metrics.precision_score(test_labelVoice, predictionTreeVoiceRS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. KNN con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a usar un KNN como clasificador para nuestro Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Pipeline con el imputer como primer paso, y como segundo paso, el clasificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the pipeline as a set of tuples\n",
    "estimatorKNNRS = Pipeline([(\"imputer\", Imputer(missing_values='NaN',\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"RSKNN\", neighbors.KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos los parámetros del algoritmo de KNN que queremos que el RandomizedSearch tenga en cuenta a la hora de buscar la configuración óptima. En el algoritmo KNeighborsClassifier no se nos permite elegir un random_state como en el caso del árbol para poder hacer reproducibles nuestros experimentos, por lo que solo usaremos la semilla en el proceso de validación cruzada que se realiza en el RandomizedSearch.\n",
    "\n",
    "En nuestro caso, para el KNN hemos añadido el número de vecinos, y el tipo de métrica a utilizar para valorar las distancias de los vecinos (puede ser la distancia o la inversa de la distancia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNNRS = RandomizedSearchCV(\n",
    "    estimator = estimatorKNNRS,\n",
    "    param_distributions = \n",
    "        { 'RSKNN__n_neighbors' : [1,2,3,4,5], 'RSKNN__weights': ['uniform','distance'] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entrenamos, validamos y obtenemos el accuracy en los datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsKNNVoiceRS = clfKNNRS.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoiceRS = clfKNNRS.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN with RS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoiceRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuál ha sido la mejor configuración de parámetros obtenida por el RandomizedSearch. En este caso es utilizar 4 vecinos, usando la métrica inversa para medir las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN) con RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RSKNN__n_neighbors': 4, 'RSKNN__weights': 'distance'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN) con RS:')\n",
    "clsKNNVoiceRS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos la matriz de confusión, precision y recall obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215, 102],\n",
       "       [ 81, 236]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice KNN with RS:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionKNNVoiceRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67823343848580442"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "print('Recall Voice KNN with RS:')\n",
    "metrics.recall_score(test_labelVoice, predictionKNNVoiceRS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72635135135135132"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "print('Precision Voice KNN with RS:')\n",
    "metrics.precision_score(test_labelVoice, predictionKNNVoiceRS, pos_label=\"female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, los resultados usando RandomizedSearch y GridSearch son muy similares."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
