{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanessa Navarro Coronado e Iván Sánchez Castellanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Multiclasificadores y selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a implementar un ensemble genérico, y comparar sus resultados con los obtenidos con los ensembles de la librería de scikit, además del clasificador base DecisionTree.\n",
    "\n",
    "Además, también utilizaremos distintas técnicas de selección de variables, y las intentaremos aplicar en nuestro ensemble para comprobar si los resultados mejoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# Cargamos el arbol de decision\n",
    "from sklearn import tree, base\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6342\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wisconsin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset Wisconsin de la librería scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "wisconsin = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en dataset en atributos y clase, pero esta vez utilizaremos las versiones numéricas de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributesWisc = wisconsin.data\n",
    "labelWisc = wisconsin.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este dataset, realizamos la separación de los datos en Train y Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attsWisc, test_attsWisc, train_labelWisc, test_labelWisc = train_test_split( \n",
    "    attributesWisc,\n",
    "    labelWisc,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=labelWisc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el dataset Pima, no podemos usar el que proporciona scikit porque es para un problema de regresión, por lo que lo incluiremos usando el csv de Campus Virtual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPima = pd.read_csv(\"../data/pima.csv\", dtype={ \"label\": 'category'})\n",
    "attributesPima = dfPima.drop('label', 1)\n",
    "labelPima = dfPima['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos Pima en numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attsPima=attributesPima.values\n",
    "labPima=np.array(labelPima.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este dataset, realizamos la separación de los datos en Train y Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attsPima, test_attsPima, train_labelPima, test_labelPima = train_test_split( \n",
    "    attsPima,\n",
    "    labPima,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=labelPima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementación básica de un ensemble de manera manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar un ensemble de forma similar a los ensembles de la librería Scikit, debemos crear una clase que herede de base.BaseEstimator, la cual ya presenta algunas funciones básicas como get_params y set_params, que son necesarias para su correcto funcionamiento.\n",
    "\n",
    "Una vez hecho esto, debemos inicializar los atributos de nuestro ensemble. Estos son:\n",
    "* estim: Estimador para el ensemble.\n",
    "* nEstim: Número de estimadores que usaremos en nuestro ensemble.\n",
    "* replace: Atributo booleano para indicar si el muestreo de los casos se realzará con reemplazo (True) o sin reemplazo (False). Por defecto, este atributo está inicializado a False.\n",
    "* attSample: Atributo booleano para indicar si se va a realizar muestreo de atributos (True) o no (False). Por defecto, este atributo está inicializado a False.\n",
    "* dataFrac: Fracción de los casos que tendremos en cuenta a la hora de realizar el muestreo. Por defecto, estará a un 60%.\n",
    "* attFrac: Fracción de los atributos que tendremos en cuenta a la hora de realizar el muestreo. Por defecto, estará a un 80%.\n",
    "* randomState: Semilla que usaremos para los muestreos.\n",
    "* models: Vector de modelos del ensemble.\n",
    "* atts: Vector de atributos a tener en cuenta.\n",
    "* predictions: Vector de predicciones realizadas.\n",
    "\n",
    "La siguiente función a implementar es la función fit, que se encarga del entrenamiento de los estimadores de nuestro ensemble. Como resultado de dicho entrenamiento, cada modelo entrenado será almacenado en un vector de modelos. Esta función también se encarga de realizar los correspondientes muestreos tanto de casos como de atributos, previos al entrenamiento en sí de los modelos.\n",
    "\n",
    "La función predict se encarga de realizar una predicción con cada uno de los modelos aprendidos en la fase anterior. Cada una de las predicciones será almacenada en el vector de predicciones del ensemble, y posteriormente deberá realizar un voto por mayoría para devolver la clase mayoritaria en cada uno de los casos del dataset.\n",
    "\n",
    "\n",
    "Como vemos, nuestro ensemble es genérico, y similar al Bagging, ya que en cada iteración, realiza un muestreo de los casos, entrena un modelo con él, y por último genera una predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurEnsemble(base.BaseEstimator):\n",
    "    \n",
    "    def __init__(self, estim, nEstim, randomState, dataFrac=0.6, replace=False, attSample=False, attFrac=0.8):\n",
    "        self.estim=estim #estimador\n",
    "        self.nEstim=nEstim #numero de estimadores\n",
    "        self.replace=replace #para indicar si el muestreo sera con reemplazo o sin reemplazo (sin reemplazo por defecto)\n",
    "        self.attSample=attSample #para indicar si haremos muestreo de atributos (por defecto esta desactivado)\n",
    "        self.dataFrac = dataFrac #porcentaje de casos para el muestreo (60% por defecto)\n",
    "        self.randomState=randomState #semilla para el muestreo\n",
    "        self.attFrac=attFrac #porcentaje de atributos que tendremos en cuenta (80% por defecto)\n",
    "        \n",
    "    def fit(self,trainAtts,trainLab): #funcion para entrenar los modelos\n",
    "        self.models=[] #vector de modelos\n",
    "        self.atts=[] #vector de atributos\n",
    "        \n",
    "        np.random.seed(self.randomState) #establecemos la semilla\n",
    "        \n",
    "        #convertir el dataset a un dataframe de pandas para que sea mas facil de manejar\n",
    "        trainAtts=pd.DataFrame(trainAtts) \n",
    "        trainLab=pd.DataFrame(trainLab)\n",
    "        \n",
    "        for n in range(0,self.nEstim):  \n",
    "            #hacer muestreo de los casos\n",
    "            trainAttsSample=trainAtts.sample(frac=self.dataFrac,replace=self.replace)\n",
    "            \n",
    "            #si esta activo el muestreo de atributos...\n",
    "            if self.attSample:\n",
    "                #almacenamos en una lista las columnas o atributos del dataset\n",
    "                #multiplicamos el procentaje de atributos a tener en cuenta por el numero total de atributos\n",
    "                #obtenemos una muestra de los atributos con la funcion random.choice\n",
    "                attMuestreo=np.random.choice(list(trainAtts.columns.values), \n",
    "                                             size=int(self.attFrac*len(trainAtts.columns)), \n",
    "                                             replace=False)\n",
    "                #añadimos los atributos resultantes del muestreo a nuestro vector de atributos\n",
    "                self.atts.append(attMuestreo)\n",
    "                \n",
    "                #nos quedamos con los casos del dataset cuyas columnas o atributos han sido elegidas en el muestreo de atributos\n",
    "                trainAttsSample=trainAttsSample[attMuestreo]\n",
    "                \n",
    "            #continuamos con el muestreo de los casos:\n",
    "            #ahora debemos coger los indices de los casos seleccionados en el muestreo, \n",
    "            #para poder coger esos mismos casos en las labels del dataset\n",
    "            trainLabelSample=trainLab.loc[trainAttsSample.index.values]\n",
    "            \n",
    "            #clonamos el estimador para que el objeto no sufra cambios al ir añadiendo el modelo aprendido al vector de modelos\n",
    "            e=base.clone(self.estim)\n",
    "            \n",
    "            #entrenamos el estimador con los muestreos de casos y de atributos realizados\n",
    "            e.fit(trainAttsSample,trainLabelSample)\n",
    "            \n",
    "            #añadimos el modelo entrenado al vector de modelos\n",
    "            self.models.append(e)\n",
    "            \n",
    "        \n",
    "    def predict(self,testAtts):\n",
    "        self.predictions=[] #vector de predicciones de cada modelo\n",
    "        \n",
    "        for n in range(0,self.nEstim):\n",
    "            #guardamos los atributos del test en una variable para no modificar el original\n",
    "            testAttsSample = testAtts\n",
    "            \n",
    "            #si el muestreo de atributos esta activado...\n",
    "            if self.attSample:\n",
    "                #seleccionamos todos los casos del test, pero solo cogemos los atributos obtenidos tras el muestreo correspondiente\n",
    "                testAttsSample=testAttsSample[:,self.atts[n]]\n",
    "            \n",
    "            #realizamos la prediccion con el modelo entrenado\n",
    "            pred=self.models[n].predict(testAttsSample)\n",
    "            #añadimos la prediccion a nuestro vector de predicciones\n",
    "            self.predictions.append(pred)\n",
    "        \n",
    "        #Para realizar la prediccion general, realizaremos un voto por mayoria de todas las prediciones, por eso usamos la moda\n",
    "        moda=stats.mode(self.predictions)\n",
    "        #devolvemos el resultado de aplicar la moda a las predicciones\n",
    "        return moda.mode[0]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado nuestro ensemble genérico, lo probamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = OurEnsemble(tree.DecisionTreeClassifier(random_state=seed), nEstim = 10, randomState=seed, attSample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Our Ensemble Wisc: 0.94 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "scores_ensWisc = cross_val_score(ens, attributesWisc, labelWisc, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Our Ensemble Wisc: %0.2f (+/- %0.2f)\" % (scores_ensWisc.mean(), scores_ensWisc.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Our Ensemble Pima: 0.74 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "scores_ensPima = cross_val_score(ens, attsPima, labPima, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Our Ensemble Pima: %0.2f (+/- %0.2f)\" % (scores_ensPima.mean(), scores_ensPima.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Árbol de decisión como referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tree Wisc: 0.90 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(random_state=seed)\n",
    "scores_dtW = cross_val_score(estimator=dt, X=attributesWisc, y=labelWisc, scoring=\"accuracy\", cv=3)\n",
    "print(\"Accuracy Tree Wisc: %0.2f (+/- %0.2f)\" % (scores_dtW.mean(), scores_dtW.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Tree Pima: 0.71 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "scores_dtP = cross_val_score(estimator=dt, X=attsPima, y=labPima, scoring=\"accuracy\", cv=3)\n",
    "print(\"Accuracy Tree Pima: %0.2f (+/- %0.2f)\" % (scores_dtP.mean(), scores_dtP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W: Wisconsin\n",
    "\n",
    "P: Pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagg = BaggingClassifier(tree.DecisionTreeClassifier(), n_estimators = 30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bagging W: 0.93 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "scores_baggW = cross_val_score(bagg, attributesWisc, labelWisc, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Bagging W: %0.2f (+/- %0.2f)\" % (scores_baggW.mean(), scores_baggW.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Bagging P: 0.75 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scores_baggP = cross_val_score(bagg, attsPima, labPima, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Bagging P: %0.2f (+/- %0.2f)\" % (scores_baggP.mean(), scores_baggP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest W: 0.95 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores_rfW = cross_val_score(rf, attributesWisc, labelWisc, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Random Forest W: %0.2f (+/- %0.2f)\" % (scores_rfW.mean(), scores_rfW.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Random Forest P: 0.76 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores_rfP = cross_val_score(rf, attsPima, labPima, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Random Forest P: %0.2f (+/- %0.2f)\" % (scores_rfP.mean(), scores_rfP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#boost = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(), n_estimators=30, random_state=seed) #accuracy: 0.90 (+/- 0.08)\n",
    "boost = AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=3), n_estimators=30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Boosting W: 0.97 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores_boostW = cross_val_score(boost, attributesWisc, labelWisc, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Boosting W: %0.2f (+/- %0.2f)\" % (scores_boostW.mean(), scores_boostW.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Boosting P: 0.71 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores_boostP = cross_val_score(boost, attsPima, labPima, cv=3, scoring=\"accuracy\")\n",
    "print(\"Accuracy Boosting P: %0.2f (+/- %0.2f)\" % (scores_boostP.mean(), scores_boostP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gboost = GradientBoostingClassifier(n_estimators=30, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Gradient Boosting W: 0.95 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores_gboostW = cross_val_score(gboost, attributesWisc, labelWisc, cv=5, scoring=\"accuracy\")\n",
    "print(\"Accuracy Gradient Boosting W: %0.2f (+/- %0.2f)\" % (scores_gboostW.mean(), scores_gboostW.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Gradient Boosting W: 0.76 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "scores_gboostP = cross_val_score(gboost, attsPima, labPima, cv=5, scoring=\"accuracy\")\n",
    "print(\"Accuracy Gradient Boosting W: %0.2f (+/- %0.2f)\" % (scores_gboostP.mean(), scores_gboostP.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación\n",
    "Ahora vamos a mostrar una comparativa de  los resultados obtenidos con nuestro ensemble, y los demás ensembles de scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to make a HTML table!\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def printTable(list):\n",
    "    table = \"\"\"<table>%s</table>\"\"\"\n",
    "    row = \"\"\"<tr>%s</tr>\"\"\"\n",
    "    cell = \"\"\"<td>%s</td>\"\"\"\n",
    "    report =  table % ''.join([row % (cell % x[0] + cell % x[1]) for x in results])\n",
    "    display(HTML(report))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wisconsin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Decision Tree</td><td>0.897994987469</td></tr><tr><td>Bagging</td><td>0.934939199851</td></tr><tr><td>Random Forest</td><td>0.954311705189</td></tr><tr><td>Boosting</td><td>0.971864847303</td></tr><tr><td>Gradient Boosting</td><td>0.95444401693</td></tr><tr><td>Our Ensemble</td><td>0.942003156038</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = ((\"Decision Tree\", scores_dtW.mean()), \n",
    "           (\"Bagging\", scores_baggW.mean()), \n",
    "           (\"Random Forest\", scores_rfW.mean()),\n",
    "           (\"Boosting\", scores_boostW.mean()),\n",
    "           (\"Gradient Boosting\", scores_gboostW.mean()),\n",
    "            (\"Our Ensemble\", scores_ensWisc.mean()))\n",
    "\n",
    "print('Wisconsin')\n",
    "printTable(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el algoritmo Boosting sigue siendo el mejor, pero nuestro ensemble genérico supera al clasificador base, y también al Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pima\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Decision Tree</td><td>0.708248852394</td></tr><tr><td>Bagging</td><td>0.749982138202</td></tr><tr><td>Random Forest</td><td>0.76038364519</td></tr><tr><td>Boosting</td><td>0.713594695741</td></tr><tr><td>Gradient Boosting</td><td>0.757711569476</td></tr><tr><td>Our Ensemble</td><td>0.740885416667</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = ((\"Decision Tree\", scores_dtP.mean()), \n",
    "           (\"Bagging\", scores_baggP.mean()), \n",
    "           (\"Random Forest\", scores_rfP.mean()),\n",
    "           (\"Boosting\", scores_boostP.mean()),\n",
    "           (\"Gradient Boosting\", scores_gboostP.mean()),\n",
    "            (\"Our Ensemble\", scores_ensPima.mean()))\n",
    "\n",
    "print('Pima')\n",
    "printTable(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, el algoritmo Random Forest sigue siendo el mejor, pero nuestro ensemble genérico supera al clasificador base, y también al Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Utilizar un método filter basado en rankings y la importancia de las variables para evaluar distintos subconjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar esta selección de variables, vamos usar una función de la librería de scikit llamada SelectKBest, que se encarga de seleccionar, de acuerdo a diferentes criterios, los K mejores atributos de un dataset determinado. Entre los criterios de selección que utiliza este algoritmo, están f_classif, que realiza un test F o ANOVA estadístico, chi2, que realiza el test de chi cuadrado, o mutual_info_classif, que selecciona las variables de acuerdo a su información mutua respecto a la clase. \n",
    "\n",
    "Para probarlo, vamos a llamar a la función con el criterio de Información Mutua, y vamos a decirle que nos devuelva un ranking de las 10 mejores variables. Una vez seleccionados los atributos, debemos llamar a la función fit_transform, para entrenar con los datos, y después seleccionar solo los K atributos elegidos con mayor score.\n",
    "\n",
    "Para Pima, como tiene menos variables, usaremos otras cifras más bajas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_classif, mutual_info_classif, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sW=SelectKBest(score_func=mutual_info_classif, k=10)\n",
    "bestAttributesWisc = sW.fit_transform(attributesWisc, labelWisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sP=SelectKBest(score_func=mutual_info_classif, k=5)\n",
    "bestAttributesPima = sP.fit_transform(attsPima, labPima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a usar un GridSearch para comprobar cuál es el criterio de selección que mejor score presentará. Para ello, vamos a crear un Pipeline, donde el primer paso será la selección de variables, y el segundo paso será nuestro ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatorENS = Pipeline([(\"Ranker\", SelectKBest()),\n",
    "                      (\"Ensemble\", OurEnsemble(\n",
    "                          tree.DecisionTreeClassifier(random_state=seed), \n",
    "                          nEstim = 10, \n",
    "                          randomState=seed ) )])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después creamos un objeto de la clase GridSearchCV, donde el estimador será nuestro pipeline, y su param_grid estará formado por los criterios de selección de variables f_classif, chi2 y mutual_info_classif, explicados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "skbW = GridSearchCV(\n",
    "    estimator = estimatorENS,\n",
    "    param_grid = \n",
    "        { 'Ranker__score_func' : [f_classif, chi2, mutual_info_classif], 'Ranker__k': [5,10] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "skbP = GridSearchCV(\n",
    "    estimator = estimatorENS,\n",
    "    param_grid = \n",
    "        { 'Ranker__score_func' : [f_classif, chi2, mutual_info_classif], 'Ranker__k': [3,5] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos y realizamos las predicciones, obteniendo el accuracy. Como vemos, ha mejorado considerablemente con respecto al comienzo de la práctica. Sin embargo, en Pima el accuracy desciende."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy OurEnsemble + Ranker W:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "fittedW=skbW.fit(train_attsWisc, train_labelWisc)\n",
    "predW=skbW.predict(test_attsWisc)\n",
    "print('Accuracy OurEnsemble + Ranker W:')\n",
    "metrics.accuracy_score(test_labelWisc, predW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy OurEnsemble + Ranker P:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72727272727272729"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedP=skbP.fit(train_attsPima, train_labelPima)\n",
    "predP=skbP.predict(test_attsPima)\n",
    "print('Accuracy OurEnsemble + Ranker P:')\n",
    "metrics.accuracy_score(test_labelPima, predP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos la mejor configuración de parámetros obtenida para el Ranker usando el GridSearch creado previamente. Esta es usar un número de variables k=10, y usar la función del test F como criterio de selección de variables. Y para Pima, es usar 5 variables y la función de Información Mutua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros Ranker W:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ranker__k': 10,\n",
       " 'Ranker__score_func': <function sklearn.feature_selection.univariate_selection.f_classif>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros Ranker W:')\n",
    "fittedW.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros Ranker P:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ranker__k': 5,\n",
       " 'Ranker__score_func': <function sklearn.feature_selection.mutual_info_.mutual_info_classif>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros Ranker P:')\n",
    "fittedP.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementar al menos un algoritmo de búsqueda recursiva wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar el Wrapper, debemos tener en cuenta que los subconjuntos de atributos que vamos a utilizar serán aleatorios, por lo que necesitaremos un atributo que nos diga cuándo parar de hacer iteraciones. Para ello, vamos a crear una clase que tendrá como atributos:\n",
    "* estim: Estimador que usaremos para aprender modelos y evaluar así los subconjuntos de variables.\n",
    "* nIter: Número de iteraciones que vamos a realizar. En cada iteración evaluaremos un subconjunto de variables distinto.\n",
    "* randomState: Semilla para la selección de atributos.\n",
    "* nAtts: Número de atributos que tendrán nuestros subconjuntos.\n",
    "* bestAtts: lista con los mejores atributos seleccionados.\n",
    "* maxScore: mejor score obtenido en la validación cruzada.\n",
    "\n",
    "Una vez inicializados los atributos, vamos a definir una función findBestAtts que se encargará de hacer la selección de variables. Primero realizamos un bucle for para realizar el muestreo de los atributos. El segundo bucle for es para obtener los scores de la validación cruzada realizada con nuestro estimador y el conjunto de atributos seleccionado. De esta validación cruzada, nos quedaremos con el subconjunto de variables que mejor score obtenga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurWrapper(object):\n",
    "    def __init__(self, estim, nIter, randomState, nAtts):\n",
    "        self.estim=estim #estimador\n",
    "        self.nIter=nIter #numero de iteraciones a realizar o numero de subconjuntos de variables a analizar\n",
    "        self.randomState=randomState #semilla\n",
    "        self.nAtts=nAtts #numero de variables en el subconjunto\n",
    "        \n",
    "    def findBestAtts(self, trainAtts, trainLab):\n",
    "        self.bestAtts=[] #vector de mejores atributos encontrados\n",
    "        self.maxScore=0 #para ir guardando el mejor score obtenido\n",
    "        attMuestreo=[] #vector auxiliar para ir guardando los subconjuntos de variables obtenidos\n",
    "        \n",
    "        np.random.seed(self.randomState) #establecemos la semilla\n",
    "        \n",
    "        #bucle para realizar los subconjuntos aleatorios de atributos\n",
    "        for i in range(0,self.nIter):\n",
    "            attMuestreo.append(np.random.choice(range(0,trainAtts.shape[1]), \n",
    "                                                size=self.nAtts, \n",
    "                                                replace=False))\n",
    "            #print(attMuestreo[i])\n",
    "        \n",
    "        #bucle para realizar la validacion cruzada con nuestro estimador y los atributos seleccionados\n",
    "        for i in range(0,self.nIter):\n",
    "            #el conjunto de train estara formado por todos los casos, pero solo analizando las variables elegidas\n",
    "            trainAttsSample=trainAtts[:,attMuestreo[i]]\n",
    "            \n",
    "            #realizamos una 5 validacion cruzada con el estimador y los datos con las variables seleccionadas\n",
    "            score=cross_val_score(self.estim, trainAttsSample, trainLab, cv=5, scoring=\"accuracy\")\n",
    "            \n",
    "            #nos quedamos con el subconjunto de atributos que mayor score haya obtenido\n",
    "            if score.mean()>self.maxScore:\n",
    "                self.maxScore=score.mean()\n",
    "                self.bestAtts=attMuestreo[i]\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo probamos usando nuestro ensemble y 10 subconjuntos de 10 atributos cada uno. Para Pima usaremos cifras más bajas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wW=OurWrapper(OurEnsemble(tree.DecisionTreeClassifier(random_state=seed), \n",
    "                          nEstim = 10, \n",
    "                          randomState=seed ),\n",
    "            10,seed,10)\n",
    "wW.findBestAtts(train_attsWisc,train_labelWisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wP=OurWrapper(OurEnsemble(tree.DecisionTreeClassifier(random_state=seed), \n",
    "                          nEstim = 10, \n",
    "                          randomState=seed ),\n",
    "            10,seed,5)\n",
    "wP.findBestAtts(train_attsPima,train_labelPima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos el mejor subconjunto de atributos de nuestro dataset. En este caso los mejores atributos han sido aquellos que se encuentran en las columnas 21,  4,  5,  7, 20, 18, 24, 15, 17 y 19. Y para Pima, las mejores son 7, 1, 0, 5, 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  4,  5,  7, 20, 18, 24, 15, 17, 19])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wW.bestAtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 0, 5, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wP.bestAtts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, mostramos el mejor score obtenido con la mejor combinación de atributos. En este caso, mejora muy poco con respecto al comienzo de la práctica, por lo que podemos concluir que lo mejor sería usar el ranker del apartado anterior. Sin embargo, en Pima mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94725274725274722"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wW.maxScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75077968812475004"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wP.maxScore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
