{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanessa Navarro Coronado e Iván Sánchez Castellanos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2 - Clasificación supervisada en scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre, lo primero que hacemos es importar los paquetes necesarios, e inicializar nuestra semilla para nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6342\n",
    "np.random.seed(6342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos los datos de los datasets Pima y Wisconsin. Cada uno será separado en dos conjuntos, uno con los atributos y otro con la clase del dataset. Esto es necesario para que la libreria scikit learn pueda ser utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the file path to fit your system\n",
    "dfPima = pd.read_csv(\"../data/pima.csv\", dtype={ \"label\": 'category'})\n",
    "dfAttributesPima = dfPima.drop('label', 1)\n",
    "dfLabelPima = dfPima['label']\n",
    "\n",
    "dfWisc = pd.read_csv(\"../data/wisconsin.csv\", dtype={ \"label\": 'category'})\n",
    "dfAttributesWisc = dfWisc.drop('label', 1)\n",
    "dfLabelWisc = dfWisc['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datasets, debemos separarlos en dos conjuntos de Train y Test para poder realizar nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train/test split for our experiments\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_attsPima, test_attsPima, train_labelPima, test_labelPima = train_test_split( \n",
    "    dfAttributesPima,\n",
    "    dfLabelPima,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=dfLabelPima)\n",
    "\n",
    "train_attsWisc, test_attsWisc, train_labelWisc, test_labelWisc = train_test_split( \n",
    "    dfAttributesWisc,\n",
    "    dfLabelWisc,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=dfLabelWisc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfPima = GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = { 'n_neighbors' : [1,2,3,4,5] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = 10\n",
    ")\n",
    "\n",
    "fittedPima = clfPima.fit(train_attsPima, train_labelPima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedPima.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707 (+/-0.128) for {'n_neighbors': 1}\n",
      "0.717 (+/-0.049) for {'n_neighbors': 2}\n",
      "0.721 (+/-0.067) for {'n_neighbors': 3}\n",
      "0.730 (+/-0.096) for {'n_neighbors': 4}\n",
      "0.733 (+/-0.068) for {'n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "# Get the mean score for each cv\n",
    "meansPima = fitted.cv_results_['mean_test_score']\n",
    "# Get the sd score for each cv\n",
    "stdsPima = fitted.cv_results_['std_test_score']\n",
    "# Get each specific configuration\n",
    "confPima = fitted.cv_results_['params']\n",
    "\n",
    "# Print the three things togheter\n",
    "for mean, std, params in zip(meansPima, stdsPima, confPima):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionPima = clfPima.predict(test_attsPima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82, 18],\n",
       "       [31, 23]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_labelPima, predictionPima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68181818181818177"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labelPima, predictionPima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42592592592592593"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "metrics.recall_score(test_labelPima, predictionPima, pos_label=\"tested_positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56097560975609762"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "metrics.precision_score(test_labelPima, predictionPima, pos_label=\"tested_positive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
