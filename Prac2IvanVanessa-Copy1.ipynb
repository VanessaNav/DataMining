{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vanessa Navarro Coronado e Iván Sánchez Castellanos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/kanncaa1/roc-curve-with-k-fold-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2 - Clasificación supervisada en scikit-learn --> VOICE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a estudiar el dataset Voice. Probaremos los clasificadores de Árbol de Decisión y KNN, y analizaremos cuál es mejor en cada caso. Además, trataremos de descubrir las configuraciones óptimas de dichos algoritmos, y realizaremos un breve estudio sobre ellos.\n",
    "\n",
    "Además, en la parte extra utilizaremos un Naive Bayes, usando el mismo procedimiento que seguimos para los clasificadores anteriormente citados.\n",
    "\n",
    "Para comenzar, como siempre, lo primero que hacemos es importar los paquetes necesarios, e inicializar nuestra semilla para nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always load all scipy stack packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code configures matplotlib for proper rendering\n",
    "%matplotlib inline\n",
    "mpl.rcParams[\"figure.figsize\"] = \"8, 4\"\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=6342\n",
    "np.random.seed(6342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargamos los datos del dataset Voice. Este será separado en dos conjuntos, uno con los atributos y otro con la clase del dataset. Esto es necesario para que la libreria scikit learn pueda ser utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the file path to fit your system\n",
    "dfVoice = pd.read_csv(\"../data/voice.csv\", dtype={ \"label\": 'category'})\n",
    "dfAttributesVoice = dfVoice.drop('label', 1)\n",
    "dfLabelVoice = dfVoice['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datasets, debemos dividirlos en dos conjuntos de Train y Test para poder realizar nuestros experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train/test split for our experiments\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_attsVoice, test_attsVoice, train_labelVoice, test_labelVoice = train_test_split( \n",
    "    dfAttributesVoice,\n",
    "    dfLabelVoice,\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=dfLabelVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Selección y evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección realizaremos experimentos utilizando el algoritmo GridSearch de la librería scikit-learn para descubrir las configuraciones óptimas de los clasificadores DecisionTree y KNN para el dataset Voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pasos a seguir en este apartado son:\n",
    "* Crear un objeto de la clase GridSearchCV, al que le pasaremos:\n",
    "    - el estimador que vamos a utilizar (DecisionTree o KNN), \n",
    "    - los hiperparámetros del clasificador que queremos tener en cuenta a la hora de buscar la configuración óptima.\n",
    "    - También debemos indicar qué tipo de métrica usaremos para valorar las configuraciones,\n",
    "    - cuántos folds se deben realizar en el proceso de validación cruzada que realiza el GridSearchCV. Si en este campo especificamos un objeto de la clase StratifiedKFold con 10 folds y nuestra semilla, podrá realizar un proceso de validación cruzada estratificada.\n",
    "    - iid = False, para que la evaluación de los resultados se haga sobre una media aritmética, y no sobre una media ponderada.\n",
    "* Entrenar y validar el clasificador con los datos de nuestro dataset, y analizar los resultados obtenidos (accuracy, precision y recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Árbol de decisión con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con el clasificador DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el arbol de decision\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí definimos nuestro GridSearch con los parámetros elegidos. Como estamos usando el clasificador DecisionTree, podemos pasarle como parámetro de 'random_state' nuestra semilla para poder hacer reproducibles nuestros experimentos. \n",
    "\n",
    "En nuestro caso hemos elegido los parámetros 'criterion' (puede ser \"gini\", que usa la impureza Gini como función, o “entropy”, usando la ganancia de información), 'max_depth' (para indicar la máxima profundidad del árbol), y 'min_samples_leaf' (para indicar el número mínimo de ejemplos que queremos que haya en cada hoja del árbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTree = GridSearchCV(\n",
    "    estimator = tree.DecisionTreeClassifier(random_state=seed),\n",
    "    param_grid =\n",
    "        {'criterion': [\"entropy\",\"gini\"],'max_depth': [3, 5, 10, None], 'min_samples_leaf': [3,5,10]},\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si asignamos el valor 'None' al parámetro 'max_depth', el clasificador intentará llegar a la máxima profundidad del árbol por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo ejecutamos con el dataset para entrenar el clasificador con el conjunto de Train, validamos con nuestro conjunto de Test, y después imprimimos el accuracy obtenido con la mejor configuración de parámetros del árbol encontrada por nuestro GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoice = clfTree.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoice = clfTree.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96488353332661081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can use it as the input of a cross-val scorer\n",
    "cross_val_score(clfTree, train_attsVoice, train_labelVoice).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, nos parece interesante mostrar la mejor configuración de los parámetros del árbol que ha encontrado el GridSearch. En este caso, la mejor configuración es utilizar el criterio de entropía para evaluar las variables del árbol, emplear una profundidad máxima del árbol de 5, y un número mínimo de ejemplos por hoja igual a 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree):')\n",
    "clsTreeVoice.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del accuracy, también es interesante mostrar la matriz de confusión obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice Tree:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[307,  10],\n",
       "       [ 15, 302]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice Tree:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. KNN con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a usar un KNN como clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos los parámetros del algoritmo de KNN que queremos que el GridSearch tenga en cuenta a la hora de buscar la configuración óptima. En el algoritmo KNeighborsClassifier no se nos permite elegir un random_state como en el caso del árbol para poder hacer reproducibles nuestros experimentos, por lo que solo usaremos la semilla en el proceso de validación cruzada que se realiza en el GridSearch.\n",
    "\n",
    "En nuestro caso, para el KNN hemos añadido el número de vecinos, y el tipo de métrica a utilizar para valorar las distancias de los vecinos (puede ser la distancia o la inversa de la distancia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNN = GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = \n",
    "        { 'n_neighbors' : [1,2,3,4,5], 'weights': ['uniform','distance'] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entrenamos, validamos y obtenemos el accuracy en los datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsKNNVoice = clfKNN.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoice = clfKNN.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69771044110562119"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can use it as the input of a cross-val scorer\n",
    "cross_val_score(clfKNN, train_attsVoice, train_labelVoice).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuál ha sido la mejor configuración de parámetros obtenida por el GridSearch. En este caso es utilizar 4 vecinos, usando la métrica distance para medir las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN):')\n",
    "clsKNNVoice.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos la matriz de confusión obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice KNN:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215, 102],\n",
       "       [ 81, 236]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice KNN:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionKNNVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Comparativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado intentaremos analizar cuál de los clasificadores ha obtenido mejores resultados en el dataset estudiado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset Pima los resultados de accuracy para el árbol de decisión y el KNN con k=5, son: \n",
    "* Accuracy Voice Tree: 0.9605678233438486\n",
    "* Accuracy Voice 4-NN: 0.71135646687697163\n",
    "\n",
    "Por tanto, podemos concluir que el mejor modelo es el obtenido con el árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Estudio de los algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado vamos a estudiar invidualmente los algoritmos:\n",
    "* En KNN, estudiaremos los parámetros aprendidos por el clasificador, realizando varias pruebas con distintas configuraciones de parámetros y analizando los resultados. Analizaremos el dataset Voice, y compararemos con el estudio realizado con Pima y Wisconsin.\n",
    "* Para el árbol, estudiaremos los parámetros aprendidos por el clasificador, y también su estructura. Analizaremos las estructuras del clasificador con la configuración óptima y otra con una configuración suboptima, y valoraremos los resultados.\n",
    "\n",
    "Para analizarlos, primero vamos a crear una funcion getScores que será similar a nuestra implementación del GridSearch pero más sencilla. Simplemente obtendremos los scores usando los distintos parámetros del clasificador. No realizamos proceso de validación cruzada, solamente usamos el holdout que teníamos al principio de la práctica.\n",
    "\n",
    "Después obtenemos tiempo y accuracy para las configuraciones, y realizaremos una comparativa de todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from time import time\n",
    "\n",
    "def getScores(estim,paramG,train_atts,train_label,test_atts,test_label):\n",
    "    \n",
    "    scores=[] #para almacenar los resultados de accuracy a devolver\n",
    "    exTimes=[] #para almacenar los tiempos a devolver\n",
    "    \n",
    "    #Generamos las configuraciones de parametros como en GridS\n",
    "    items = paramG.items()\n",
    "    keys, values = zip(*items)\n",
    "    v = list(product(*values))\n",
    "    \n",
    "    # Recorremos las configuraciones y almacenamos los resultados\n",
    "    for param in v:\n",
    "        \n",
    "        params = dict(zip(keys,param))\n",
    "        estim.set_params(**params)\n",
    "        \n",
    "        timeSum=0 #variable intermedia para mostrar la media de los tiempos\n",
    "        \n",
    "        for i in range(0,100):\n",
    "            start = time()\n",
    "            estim.fit(train_atts,train_label) #entrenamos con el conjunto de Train\n",
    "            predictions = estim.predict(test_atts) #array de predicciones para el conjunto de Test\n",
    "            end = time()\n",
    "            timeSum += (end - start)\n",
    "        exTimes.append(timeSum/100) #añadimos al array de tiempos la media de las 100 medidas de tiempo realizadas\n",
    "        \n",
    "        comparison = np.sum(predictions == test_label) #comparamos predicciones con test_label y sumamos los aciertos\n",
    "        accuracy = comparison / len(predictions) #dividimos entre los casos totales\n",
    "        scores.append(accuracy) #añadimos al array de scores el accuracy obtenido con la configuración de parámetros actual\n",
    "        \n",
    "    return (v,scores,exTimes) #devolvemos las configuraciones, los accuracys y los tiempos de cada configuracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Estudio del algoritmo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este clasificador, usaremos las combinaciones teniendo en cuenta el número de vecinos (k=1,5,10,50,100) y el método de evaluación de las distancias (uniforme o inversa de la distancia). Para ello usaremos nuestra función getScores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.1. KNN con Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho esto, podemos hacer una comparativa de los resultados obtenidos para todas las configuraciones del clasificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paramsKNNVoice</th>\n",
       "      <th>scoresKNNVoice</th>\n",
       "      <th>exTimesKNNVoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(uniform, 1)</td>\n",
       "      <td>0.695584</td>\n",
       "      <td>0.008447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(uniform, 5)</td>\n",
       "      <td>0.708202</td>\n",
       "      <td>0.009291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(uniform, 10)</td>\n",
       "      <td>0.703470</td>\n",
       "      <td>0.011899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(uniform, 50)</td>\n",
       "      <td>0.679811</td>\n",
       "      <td>0.016622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(uniform, 100)</td>\n",
       "      <td>0.692429</td>\n",
       "      <td>0.023539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(distance, 1)</td>\n",
       "      <td>0.695584</td>\n",
       "      <td>0.008079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(distance, 5)</td>\n",
       "      <td>0.709779</td>\n",
       "      <td>0.009332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(distance, 10)</td>\n",
       "      <td>0.714511</td>\n",
       "      <td>0.010247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(distance, 50)</td>\n",
       "      <td>0.690852</td>\n",
       "      <td>0.020599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(distance, 100)</td>\n",
       "      <td>0.689274</td>\n",
       "      <td>0.034512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paramsKNNVoice  scoresKNNVoice  exTimesKNNVoice\n",
       "0     (uniform, 1)        0.695584         0.008447\n",
       "1     (uniform, 5)        0.708202         0.009291\n",
       "2    (uniform, 10)        0.703470         0.011899\n",
       "3    (uniform, 50)        0.679811         0.016622\n",
       "4   (uniform, 100)        0.692429         0.023539\n",
       "5    (distance, 1)        0.695584         0.008079\n",
       "6    (distance, 5)        0.709779         0.009332\n",
       "7   (distance, 10)        0.714511         0.010247\n",
       "8   (distance, 50)        0.690852         0.020599\n",
       "9  (distance, 100)        0.689274         0.034512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsKNNVoice,scoresKNNVoice,exTimesKNNVoice=getScores(neighbors.KNeighborsClassifier(),\n",
    "                                                     { 'weights': ['uniform','distance'], 'n_neighbors' : [1,5,10,50,100] },\n",
    "                                                     train_attsVoice,train_labelVoice,\n",
    "                                                     test_attsVoice,test_labelVoice)\n",
    "resultadosKNNVoice=pd.DataFrame(list(zip(paramsKNNVoice,scoresKNNVoice,exTimesKNNVoice)))\n",
    "resultadosKNNVoice.columns=['paramsKNNVoice','scoresKNNVoice','exTimesKNNVoice']\n",
    "resultadosKNNVoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar, la configuración con mejor accuracy sería usar k=10 y la inversa de la distancia (fila 7 de la tabla). Por tanto, si aumentamos K, podríamos pensar que se mejora el accuracy, pero solo hasta cierto punto, porque con K=100 (fila 9) ya obtenemos un accuracy peor. De forma general, usar un K muy alto se asemeja a un clasificador ZeroR, ya que ambos utilizarían la estrategia de clasificación por la clase mayoritaria.\n",
    "\n",
    "Además, debemos tener en mente que cuanto mayor sea el parámetro K, mayor será el tiempo de ejecución. En este caso, el tiempo de ejecución se corresponde con el tiempo de realizar la predicción con el conjunto de Test. Esto es debido a que el entrenamiento en el clasificador KNN es muy rápido, ya que solo consiste en copiar la base de datos de los casos de Train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. Estudio del algoritmo DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este clasificador, realizaremos las combinaciones teniendo en cuenta el criterio (entropía o gini), la profundidad máxima del árbol, y el número mínimo de ejemplos por hoja. \n",
    "\n",
    "Para analizar la estructura de los árboles generados con las diferentes combinaciones de parámetros, vamos a usar (además de nuestra función getScores) la función getTreeNodes, que nos devuelve el número de nodos que presenta un árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTreeNodes(estim,paramG,train_atts,train_label):\n",
    "    \n",
    "    nodes=[] #para almacenar el numero de nodos de cada arbol generado\n",
    "    \n",
    "    #Generamos las configuraciones de parametros como en GridS\n",
    "    items = paramG.items()\n",
    "    keys, values = zip(*items)\n",
    "    v = list(product(*values))\n",
    "    \n",
    "    # Recorremos las configuraciones y almacenamos los resultados\n",
    "    for param in v:\n",
    "        \n",
    "        params = dict(zip(keys,param))\n",
    "        estim.set_params(**params)\n",
    "\n",
    "        estim.fit(train_atts,train_label) #entrenamos con el conjunto de Train\n",
    "        \n",
    "        nodes.append(estim.tree_.node_count) #añadimos al array el numero de nodos del arbol actual\n",
    "        \n",
    "    return (v,nodes) #devolvemos las configuraciones de los arboles y el numero de nodos de cada uno de ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1. Árbol con Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer una comparativa de los resultados obtenidos para todas las configuraciones del árbol de clasificación, junto con la complejidad de cada árbol generado (representada por el número de nodos de cada árbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsTreeVoice,scoresTreeVoice,exTimesTreeVoice=getScores(tree.DecisionTreeClassifier(random_state=seed),\n",
    "                                                        {'criterion': [\"entropy\",\"gini\"],\n",
    "                                                         'max_depth': [3, 5, 10], \n",
    "                                                         'min_samples_leaf': [3,5,10]},\n",
    "                                                        train_attsVoice,train_labelVoice,\n",
    "                                                        test_attsVoice,test_labelVoice)\n",
    "resultadosTreeVoice=pd.DataFrame(list(zip(paramsTreeVoice,scoresTreeVoice,exTimesTreeVoice)))\n",
    "resultadosTreeVoice.columns=['paramsTreeVoice','scoresTreeVoice','exTimesTreeVoice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paramsTreeVoice</th>\n",
       "      <th>scoresTreeVoice</th>\n",
       "      <th>exTimesTreeVoice</th>\n",
       "      <th>nodesTreeVoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(entropy, 3, 3)</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.032279</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(entropy, 3, 5)</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(entropy, 3, 10)</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.030794</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(entropy, 5, 3)</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(entropy, 5, 5)</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(entropy, 5, 10)</td>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(entropy, 10, 3)</td>\n",
       "      <td>0.955836</td>\n",
       "      <td>0.040192</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(entropy, 10, 5)</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(entropy, 10, 10)</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.038568</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(gini, 3, 3)</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(gini, 3, 5)</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(gini, 3, 10)</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(gini, 5, 3)</td>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.021529</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(gini, 5, 5)</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.021441</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(gini, 5, 10)</td>\n",
       "      <td>0.963722</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(gini, 10, 3)</td>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(gini, 10, 5)</td>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.027591</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(gini, 10, 10)</td>\n",
       "      <td>0.963722</td>\n",
       "      <td>0.025443</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      paramsTreeVoice  scoresTreeVoice  exTimesTreeVoice  nodesTreeVoice\n",
       "0     (entropy, 3, 3)         0.944795          0.032279              15\n",
       "1     (entropy, 3, 5)         0.944795          0.030422              15\n",
       "2    (entropy, 3, 10)         0.944795          0.030794              15\n",
       "3     (entropy, 5, 3)         0.957413          0.039179              53\n",
       "4     (entropy, 5, 5)         0.957413          0.038390              51\n",
       "5    (entropy, 5, 10)         0.960568          0.037523              41\n",
       "6    (entropy, 10, 3)         0.955836          0.040192              91\n",
       "7    (entropy, 10, 5)         0.957413          0.039979              77\n",
       "8   (entropy, 10, 10)         0.962145          0.038568              53\n",
       "9        (gini, 3, 3)         0.962145          0.015112              15\n",
       "10       (gini, 3, 5)         0.962145          0.015010              15\n",
       "11      (gini, 3, 10)         0.962145          0.014940              15\n",
       "12       (gini, 5, 3)         0.957413          0.021529              51\n",
       "13       (gini, 5, 5)         0.962145          0.021441              51\n",
       "14      (gini, 5, 10)         0.963722          0.021654              43\n",
       "15      (gini, 10, 3)         0.960568          0.027919              91\n",
       "16      (gini, 10, 5)         0.965300          0.027591              85\n",
       "17     (gini, 10, 10)         0.963722          0.025443              65"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsTreeVoice,nodesTreeVoice=getTreeNodes(tree.DecisionTreeClassifier(random_state=seed),\n",
    "                                          {'criterion': [\"entropy\",\"gini\"],\n",
    "                                           'max_depth': [3, 5, 10], \n",
    "                                           'min_samples_leaf': [3,5,10]},\n",
    "                                          train_attsVoice,train_labelVoice)\n",
    "resultadosTreeVoice.assign(nodesTreeVoice = nodesTreeVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en la tabla, la configuración con mayor accuracy sería la que se encuentra en la fila 16: criterio gini, máxima profundidad del árbol igual a 10 y mínimo número de ejemplos por hoja igual a 5.\n",
    "\n",
    "Sin embargo, esta configuración genera un árbol muy complejo, con más de 80 nodos. Por tanto, podríamos compararlo con el segundo mejor árbol generado (árbol de la fila 14 de la tabla), el cual presenta un accuracy algo más bajo, pero está compuesto por la mitad de nodos. Este caso necesitaría una profundidad máxima del árbol igual a 5, y un número mínimo de ejemplos por hoja igual a 10, para conseguir (casi) igualar el accuracy al del árbol de la fila 16, por lo que sería interesante seleccionar el árbol más simple para nuestra clasificación. Además, su tiempo de ejecución es menor.\n",
    "\n",
    "De esta forma podemos ver que debemos tener en cuenta otros factores además del accuracy para poder evaluar la efectividad del clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. Conclusiones del estudio de los algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras el estudio de los algoritmos, nos hemos dado cuenta de que dependiendo del problema y del dataset al que nos enfrentemos, es posible que la configuración de parámetros óptima para un determinado algoritmo no siempre sea la misma. \n",
    "* En el KNN con el dataset Pima hemos visto que es bueno aumentar la vecindad (hasta cierto punto). Sin embargo, con el dataset Wisconsin los resultados empeoran mucho al usar vecindades grandes, y además se consumía demasiado tiempo.\n",
    "* Con el árbol de decisión, hemos aprendido que es una buena práctica observar las configuraciones subóptimas del clasificador para obtener árboles más sencillos, en los cuales el tiempo de ejecución es menor y obtienen rendimientos similares a árboles más grandes.\n",
    "* Con este nuevo dataset Voice, hemos visto que usando KNN como clasificador, nos ocurre algo parecido a lo que pasaba con Pima, y en el árbol hemos llegado a la misma conclusión que llegamos con Pima y Wisconsin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementación de GridSearch manualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado realizamos una implementación manual de un GridSearh básico, con su constructor, y las funciones fit y predict, que son las que utilizamos en esta práctica.\n",
    "\n",
    "Nuestra clase GridS tiene como atributos:\n",
    "* estim: estimador o clasificador a evaluar,\n",
    "* crossval: cómo realizar el proceso de validación cruzada durante la evaluación,\n",
    "* score: tipo de métrica a utilizar para la evaluación de la configuración óptima,\n",
    "* keys: nombre de los parámetros del clasificador a tener en cuenta en la evaluación,\n",
    "* v: lista con todas las posibles combinaciones de parámetros del clasificador,\n",
    "* bestScore: mejor puntuación obtenida con la configuración de parámetros del clasificador,\n",
    "* bestParams: mejor configuración de parámetros del clasificador.\n",
    "\n",
    "La función fit se encarga de realizar la validación cruzada para cada una de las diferentes combinaciones de parámetros contenidas en self.v, obteniendo así aquella configuración que ofrezca una mayor puntuación. Una vez obtenida, entrena el clasificador con el conjunto de datos que se le pasa como parámetro a la función fit.\n",
    "\n",
    "La función predict simplemente hace la validación del clasificador con el conjunto que reciba como parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "\n",
    "class GridS(object):\n",
    "    def __init__(self,estim, paramG, score, crossval):\n",
    "        items = paramG.items()\n",
    "        self.keys, values = zip(*items)\n",
    "        self.v = list(product(*values))\n",
    "        self.estim=estim\n",
    "        self.crossval=crossval\n",
    "        self.score=score\n",
    "            \n",
    "    def fit(self,atts,label):\n",
    "        self.bestScore=0\n",
    "        for param in self.v:\n",
    "            params = dict(zip(self.keys,param))\n",
    "            self.estim.set_params(**params)\n",
    "            scores = cross_val_score(estimator=self.estim, \n",
    "                                     X=atts, y=label, \n",
    "                                     scoring=self.score, \n",
    "                                     cv=self.crossval)\n",
    "            if self.bestScore < scores.mean():\n",
    "                self.bestScore=scores.mean()\n",
    "                self.bestParams=params\n",
    "        self.estim.set_params(**self.bestParams)\n",
    "        self.estim.fit(atts,label)\n",
    "    \n",
    "    def predict(self, atts):\n",
    "        return self.estim.predict(atts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. KNN con GridSearch manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que hicimos anteriormente con el GridSearch de scikit, creamos un objeto de la clase GridS. Le pasamos un clasificador KNN, y le indicamos que obtenga la mejor configuración de parámetros atendiendo al número de vecinos (de 1 a 5 vecinos), y el tipo de métrica a utilizar para valorar la distancia (uniforme o inversa de la distancia). El tipo de métrica a utilizar será de nuevo el accuracy, y utilizaremos un proceso de validación cruzada estratificada de 10 folds, con nuestra semilla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsKNN = GridS(\n",
    "    estim = neighbors.KNeighborsClassifier(),\n",
    "    paramG = \n",
    "        { 'n_neighbors' : [1,2,3,4,5], 'weights': ['uniform','distance'] },\n",
    "    score = 'accuracy',\n",
    "    crossval = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación utilizamos nuestro GridS en el dataset y evaluamos los resultados. Como vemos, son los mismos que obtuvimos usando el GridSearch de scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsKNNVoiceGS = gsKNN.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoiceGS = gsKNN.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN + GridS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoiceGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN + GridS):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN + GridS):')\n",
    "gsKNN.bestParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Árbol de decisión con GridSearch manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que hicimos anteriormente con el GridSearch de scikit, creamos un objeto de la clase GridS. Le pasamos un clasificador DecisionTree, y le indicamos que obtenga la mejor configuración de parámetros atendiendo al criterio de evaluación (entrioía o gini), la máxima profundidad del árbol, y el número mínimo de ejemplos por hoja. El tipo de métrica a utilizar será de nuevo el accuracy, y utilizaremos un proceso de validación cruzada estratificada de 10 folds, con nuestra semilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsTree=GridS(\n",
    "    estim = tree.DecisionTreeClassifier(random_state=seed),\n",
    "    paramG={'criterion': [\"entropy\",\"gini\"],'max_depth': [3, 5, 10, None], 'min_samples_leaf': [3,5,10]},\n",
    "    score='accuracy',\n",
    "    crossval=StratifiedKFold(n_splits=10, shuffle=False, random_state=seed)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación utilizamos nuestro GridS en el dataset y evaluamos los resultados. Como vemos, son los mismos que obtuvimos usando el GridSearch de scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree + GridS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoiceGS = gsTree.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoiceGS = gsTree.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree + GridS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoiceGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree + GridS):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree + GridS):')\n",
    "gsTree.bestParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extras: Algoritmo RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección realizaremos experimentos utilizando el algoritmo RandomizedSearch de la librería scikit-learn para descubrir las configuraciones óptimas de los clasificadores DecisionTree y KNN para nuestro dataset. Seguiremos el mismo proceso que hicimos con GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Árbol de decisión con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí definimos nuestro RandomizedSearch con los parámetros elegidos. Como estamos usando el clasificador DecisionTree, podemos pasarle como parámetro de 'random_state' nuestra semilla para poder hacer reproducibles nuestros experimentos. \n",
    "\n",
    "En nuestro caso hemos elegido los parámetros 'criterion' (puede ser \"gini\", que usa la impureza Gini como función, o “entropy”, usando la ganancia de información), 'max_depth' (para indicar la máxima profundidad del árbol), y 'min_samples_leaf' (para indicar el número mínimo de ejemplos que queremos que haya en cada hoja del árbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTreeRS = RandomizedSearchCV(\n",
    "    estimator = tree.DecisionTreeClassifier(random_state=seed),\n",
    "    param_distributions =\n",
    "        {'criterion': [\"entropy\",\"gini\"],'max_depth': [3, 5, 10, None], 'min_samples_leaf': [3,5,10]},\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos nuestro gridsearch con el dataset para entrenar el clasificador con el conjunto de Train, validamos con nuestro conjunto de Test, y después imprimimos el accuracy obtenido con la mejor configuración de parámetros del árbol encontrada por nuestro RandomizedSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9605678233438486"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsTreeVoiceRS = clfTreeRS.fit(train_attsVoice, train_labelVoice)\n",
    "predictionTreeVoiceRS = clfTreeRS.predict(test_attsVoice)\n",
    "print('Accuracy Voice Tree with RS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionTreeVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, nos parece interesante mostrar la mejor configuración de los parámetros del árbol que ha encontrado el GridSearch. En este caso, la mejor configuración es utilizar el criterio de entropía para evaluar las variables del árbol, emplear una profundidad máxima del árbol de 5, y un número mínimo de ejemplos por hoja igual a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice Tree) con RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 5}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice Tree) con RS:')\n",
    "clfTreeRS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del accuracy, también es interesante mostrar la matriz de confusión obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice Tree with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[305,  12],\n",
       "       [ 15, 302]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice Tree with RS:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionTreeVoiceRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. KNN con preprocesamiento de los datos durante la validación cruzada (transformers y pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a usar un KNN como clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos los parámetros del algoritmo de KNN que queremos que el RandomizedSearch tenga en cuenta a la hora de buscar la configuración óptima. En el algoritmo KNeighborsClassifier no se nos permite elegir un random_state como en el caso del árbol para poder hacer reproducibles nuestros experimentos, por lo que solo usaremos la semilla en el proceso de validación cruzada que se realiza en el RandomizedSearch.\n",
    "\n",
    "En nuestro caso, para el KNN hemos añadido el número de vecinos, y el tipo de métrica a utilizar para valorar las distancias de los vecinos (puede ser la distancia o la inversa de la distancia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfKNNRS = RandomizedSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_distributions = \n",
    "        { 'n_neighbors' : [1,2,3,4,5], 'weights': ['uniform','distance'] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entrenamos, validamos y obtenemos el accuracy en los datos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71135646687697163"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsKNNVoiceRS = clfKNNRS.fit(train_attsVoice, train_labelVoice)\n",
    "predictionKNNVoiceRS = clfKNNRS.predict(test_attsVoice)\n",
    "print('Accuracy Voice KNN with RS:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionKNNVoiceRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuál ha sido la mejor configuración de parámetros obtenida por el RandomizedSearch. En este caso es utilizar 4 vecinos, usando la métrica distance para medir las distancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice KNN) con RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice KNN) con RS:')\n",
    "clfKNNRS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación mostramos la matriz de confusión obtenida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix Voice KNN with RS:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215, 102],\n",
       "       [ 81, 236]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix Voice KNN with RS:')\n",
    "metrics.confusion_matrix(test_labelVoice, predictionKNNVoiceRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Naive Bayes con GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a usar el GridSearchCV con el clasificador Naive Bayes, concretamente el algoritmo GaussianNB, el cual se utiliza para clasificar con variables continuas. Este algoritmo solo recibe como parámetro 'priors' las probabilidades a priori de la clase. En nuestro caso, crearemos un GridSearch con el parámetro 'priors' fijado a diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfNB = GridSearchCV(\n",
    "    estimator = GaussianNB(),\n",
    "    param_grid = \n",
    "        { 'priors':[[0.3,0.7],[0.5,0.5],[0.9,0.1],[0.6,0.4]] },\n",
    "    scoring = 'accuracy',\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=False, random_state=seed), \n",
    "    iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero entrenamos nuestro clasificador con el dataset, y observamos que el accuracy es menor que el obtenido con el árbol de decisión, y peor que el obtenido con el KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Voice NB:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8848580441640379"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit and use the pipeline as usual\n",
    "clsNBVoice = clfNB.fit(train_attsVoice, train_labelVoice)\n",
    "predictionNBVoice = clfNB.predict(test_attsVoice)\n",
    "print('Accuracy Voice NB:')\n",
    "metrics.accuracy_score(test_labelVoice, predictionNBVoice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos la mejor configuración de parámetros obtenida por el GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración de parámetros (Voice NB):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'priors': [0.3, 0.7]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Mejor configuración de parámetros (Voice NB):')\n",
    "clsNBVoice.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
